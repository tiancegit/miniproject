{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lee/Web_crawler/venv/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /usr/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nbsodj.html.body.h1\\nbsodj.body.h1 \\nbsodj.html.h1\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 安装BeautifulSoup 4。也称为BS4\n",
    "\n",
    "# sudo apt-get install python-bs4\n",
    "\n",
    "# pip install beautifulsoup4\n",
    "\n",
    "# python3 安装bs4\n",
    "\n",
    "# pip3 install beautifulsoup4\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "# 打开链接，保存为对象。\n",
    "html = urlopen(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "# 转换为BS4对象。方便解析。\n",
    "bsodj = BeautifulSoup(html.read())\n",
    "print(bsodj.h1)\n",
    "\n",
    "# 与下面的所有的函数调用都可以产生同样的结果。类似树状结构。可以从根，分节点，结果。分层指定。\n",
    "\n",
    "\"\"\"\n",
    "bsodj.html.body.h1\n",
    "bsodj.body.h1 \n",
    "bsodj.html.h1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lee/Web_crawler/venv/lib/python3.5/site-packages/bs4/element.py:1050: UserWarning: .nonExistentTag is deprecated, use .find(\"nonExistent\") instead.\n",
      "  tag_name, tag_name))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'someTag'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a268e2f7d022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 会返回一个None对象。检查并处理这个对象很有必要性。不检查，直接调用这个None对象的子标签。会出现报错。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsodj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonExistentTag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msomeTag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# AttributeError: 'NoneType' object has no attribute 'someTag'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'someTag'"
     ]
    }
   ],
   "source": [
    "# nonExistentTag 是虚拟的标签，Bs4对象里实际并没有这个标签。\n",
    "\n",
    "print(bsodj.nonExistentTag)\n",
    "\n",
    "# 会返回一个None对象。检查并处理这个对象很有必要性。不检查，直接调用这个None对象的子标签。会出现报错。\n",
    "\n",
    "print(bsodj.nonExistentTag.someTag)\n",
    "\n",
    "# AttributeError: 'NoneType' object has no attribute 'someTag'\n",
    "# 避免两种情况的异常。对这两种情形进行检查。\n",
    "try:\n",
    "    # 尝试获取标签。\n",
    "    badContent = bsodj.nonExistentTag.anotherTag\n",
    "except AttributeError as e:\n",
    "    # 如果出现属性错误。返回一个报错。\n",
    "    print(\"Tag was not found\")\n",
    "else:\n",
    "    # 如果为None。返回提示\n",
    "    if badContent == None:\n",
    "        print(\"Tag was not found\")\n",
    "    else:\n",
    "        print(badContent)\n",
    "    \n",
    "# 需要考虑到各种不同的可能性。并做好错误处理。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna\n",
      "Pavlovna Scherer\n",
      "Empress Marya\n",
      "Fedorovna\n",
      "Prince Vasili Kuragin\n",
      "Anna Pavlovna\n",
      "St. Petersburg\n",
      "the prince\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "the prince\n",
      "the prince\n",
      "Prince Vasili\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "Wintzingerode\n",
      "King of Prussia\n",
      "le Vicomte de Mortemart\n",
      "Montmorencys\n",
      "Rohans\n",
      "Abbe Morio\n",
      "the Emperor\n",
      "the prince\n",
      "Prince Vasili\n",
      "Dowager Empress Marya Fedorovna\n",
      "the baron\n",
      "Anna Pavlovna\n",
      "the Empress\n",
      "the Empress\n",
      "Anna Pavlovna's\n",
      "Her Majesty\n",
      "Baron\n",
      "Funke\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "the Empress\n",
      "The prince\n",
      "Anatole\n",
      "the prince\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "Anna Pavlovna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lee/miniproject/Web_crawler/venv/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /usr/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# 一种可行但不美观的解析方式，网站改版后，可能会导致爬虫失效。\n",
    "#bsodj.findAll(\"table\")[4].findAll(\"tr\")[2].find(td).findAll(\"div\")[1].find(\"a\")\n",
    "\n",
    "# 可以尝试的解决方式。\n",
    "\"\"\"\n",
    "1. 寻找”打印此页“ 按钮。或查看网站有没有HTML样式更友好的移动端站点。 请求头修改为移动设备，接收移动端页面。\n",
    "2. 寻找隐藏在JS文件中的信息。是否用过JS获取信息。是否前后端分离。\n",
    "3. 网页标题或许可以在url链接中获取得到。\n",
    "4. 寻找其它数据源，或最原始的数据源。\n",
    "\"\"\"\n",
    "\n",
    "# 根据Css元素样式进行解析。\n",
    "\"\"\"\n",
    "<span class=\"green\"></span>\n",
    "<span class=\"red\"></span>\n",
    "\"\"\"\n",
    "# 可以通过class属性的值。轻松区分出两种不同的标签。例如可以通过BS4抓取网页上的红色文字。而绿色的一个都不抓取。\n",
    "\n",
    "# 创建爬虫爬取下面这个网页。对话内容都是红色的。人物名称是红色的。\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"http://www.pythonscraping.com/pages/warandpeace.html\"\n",
    "html = urlopen(url)\n",
    "bsObj = BeautifulSoup(html)\n",
    "\n",
    "namelist = bsObj.findAll(\"span\", {\"class\":\"green\"})\n",
    "for name in namelist:\n",
    "    print(name.get_text())\n",
    "\n",
    "# 会根据《战争与和平》中出场人物顺序显示所以的名字。 bsObj.tagname 只能获取页面中第一个指定的标签。\n",
    "# 调用bsObj.findAll(tagname, tagAttributes) 可以获取页面中所有指定的标签。\n",
    "# .get_text()可以把超链接，段落，标签都清除掉，只留下不带标签的文字。一般只在打印，存储或操作数据的时候才使用.get_text()\n",
    "# 一般都尽可能的保留HTML文档的标签结构。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'findAll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2594d19309a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 这个两个函数非常相似。在文档中对两者的定义是：\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'findAll' is not defined"
     ]
    }
   ],
   "source": [
    "# Bs4 中的find() 和 findAll()\n",
    "\n",
    "# 这个两个函数非常相似。在文档中对两者的定义是：\n",
    "findAll(tag, attributes, recursive, text, limit, keywords)\n",
    "find(tag, attributes, recursive, text, limit, keywords)\n",
    "\n",
    "# tag 标签参数可以传入一个标签的名称或多个标签名称组成的Python列表（list） 作为参数。\n",
    "\n",
    "bsObj.findAll([\"h1\", \"h2\", \"h3\", \"h3\", \"h4\", \"h5\",\"h6\"])  # 返回一个包含HTML文档中所有标题标签的列表。\n",
    "\n",
    "# attributes 是用一个dict字典。封装一个标签的若干属性和对应的属性值。\n",
    "\n",
    "bsObj.findAll(\"span\", {\"class\":[\"green\", \"red\"]})    # 返回文档里红色和绿色两种颜色的span标签.\n",
    "\n",
    "# 递归参数 recursive 是一个布尔变量。你想抓取HTML文档标签结构里的多少层信息。 \n",
    "# 设置为True.findAll会根据要求去查询标签参数的所有子标签。以及子标签的所以子标签。\n",
    "# 如果是设置为False，FindAll只会查找文档的一级标签。 findAll 默认是支持递归查找的（recursive默认值为True。）\n",
    "# 一般不需要设置，除非是真正了解自己需要那些信息。而且抓取速度要求非常高。这时可以设置递归参数。\n",
    "\n",
    "# text 参数是用标签的文本内容去匹配的，而不是用标签的属性。\n",
    "nameList = bsObj.findAll(text=\"the prince\")     # 查找网页中包含”the prince“ 内容的标签数量。\n",
    "print(len(nameList))  # 7\n",
    "\n",
    "# limit 范围限制参数，只适用findAll(), find等价于是 findAll（limit=1）的情形。\n",
    "\n",
    "# keyword 关键词参数。可以让你选择那些具有指定属性的标签。\n",
    "allText = bsObj.findAll(id=\"text\")\n",
    "print(allText[0].get_text())\n",
    "\n",
    "\n",
    "# 关键字参数很有用。但是这是bs4在技术上的一个功能。任何用keyword参数完成的任务。都可以使用其它技术完成。\n",
    "\n",
    "#下面的代码是完全一样的。\n",
    "bsObj.findAll(id=\"text\")\n",
    "bsObj.findAll(\"\", {\"id\":\"text\"})\n",
    "\n",
    "# 使用keyword 参数通过class参数查找标签的时候。因为class是系统的保留字。所以不能作为变量名或参数名使用。\n",
    "# 运行下面的代码会因为使用了class关键字保留参数而产生一个语法错误\n",
    "\n",
    "bsObj.findAll(class=\"green\")\n",
    "\n",
    "# 可以使用Bs4提供的一个有些臃肿的方案。\n",
    "bsObj.findAll(class_=\"green\")\n",
    "# 或是用属性参数把class用引号括起来。\n",
    "bsObj.findAll(\"\", {\"class\", \"green\"})\n",
    "\n",
    "# 通过tag参数把标签列表传入.finAll()中，获取一列标签。其实就是一个”或“关系的过滤器。即是选择所有带标签1，标签2..的一系列标签。\n",
    "# 如果是标签列表很长。需要很长时间才能写完。关键词参数可以让你增加一个 ”与“ 关系的过滤器来简化工作。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs4库还有两种对象，虽然不常用，但也应该去了解一下。\n",
    "\n",
    "# NavigableString对象\n",
    "# 用来表示标签里的文章。而不是标签。（有些函数可以生成和操作NavigableString对象。而不是标签对象。）\n",
    "\n",
    "# Comment 对象\n",
    "# 用于查找HTML文档的注释标签。<!-- 类似这样的标签 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<tr><th>\n",
      "Item Title\n",
      "</th><th>\n",
      "Description\n",
      "</th><th>\n",
      "Cost\n",
      "</th><th>\n",
      "Image\n",
      "</th></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift1\"><td>\n",
      "Vegetable Basket\n",
      "</td><td>\n",
      "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
      "<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
      "</td><td>\n",
      "$15.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img1.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift2\"><td>\n",
      "Russian Nesting Dolls\n",
      "</td><td>\n",
      "Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
      "</td><td>\n",
      "$10,000.52\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img2.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift3\"><td>\n",
      "Fish Painting\n",
      "</td><td>\n",
      "If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
      "</td><td>\n",
      "$10,005.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img3.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift4\"><td>\n",
      "Dead Parrot\n",
      "</td><td>\n",
      "This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
      "</td><td>\n",
      "$0.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img4.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift5\"><td>\n",
      "Mystery Box\n",
      "</td><td>\n",
      "If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
      "</td><td>\n",
      "$1.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img6.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 导航树\n",
    "\n",
    "# findAll() 函数通过标签的名字和属性来查找标签。\n",
    "# 如果需要通过标签在文档中所在的位置来查找标签。这需要使用到导航树（Navigating Trees）\n",
    "\n",
    "# bsObj.tag.subtag.anotherSubTag  # 单一方向的导航树。 父标签.子标签.后代标签。\n",
    "\n",
    "# 子标签是父标签的下一级。而后代标签则是一个父标签下的所有级别的标签。\n",
    "# 如 tr 是 table 标签的子标签。而tr，th，span，td，img，span都是table标签的后代标签。\n",
    "\n",
    "# 一般情况下。BS4 函数都是会处理当前标签的后代标签。\n",
    "\n",
    "#bsObj.body.h1   # 选择了body标签后代中的第一个h1标签。而不会去找body外的标签。\n",
    "#bsObj.div.findAll(\"img\")    # 会找到文档中的第一个div标签。然后获取这个div后代里所有的img标签列表。\n",
    "\n",
    "# 如果只是想找出子标签。可以使用.childrenha方法。\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://www.pythonscraping.com/pages/page3.html\"\n",
    "html = urlopen(url)\n",
    "bsObj = BeautifulSoup(html, \"html.parser\")   # 需要指定解析器。\n",
    "\n",
    "for child in bsObj.find(\"table\",{\"id\":\"giftList\"}).children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift1\"><td>\n",
      "Vegetable Basket\n",
      "</td><td>\n",
      "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
      "<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
      "</td><td>\n",
      "$15.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img1.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift2\"><td>\n",
      "Russian Nesting Dolls\n",
      "</td><td>\n",
      "Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
      "</td><td>\n",
      "$10,000.52\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img2.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift3\"><td>\n",
      "Fish Painting\n",
      "</td><td>\n",
      "If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
      "</td><td>\n",
      "$10,005.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img3.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift4\"><td>\n",
      "Dead Parrot\n",
      "</td><td>\n",
      "This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
      "</td><td>\n",
      "$0.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img4.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift5\"><td>\n",
      "Mystery Box\n",
      "</td><td>\n",
      "If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
      "</td><td>\n",
      "$1.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img6.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BS4的next_siblings() 函数可以让收集表格数据变得简单了些。尤其是带标题行的表格。  直译为 下一个兄弟标签。\n",
    "# 这个函数可以调用其本身之外的兄弟标签。\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://www.pythonscraping.com/pages/page3.html\"\n",
    "html = urlopen(url)\n",
    "bsObj = BeautifulSoup(html, \"html.parser\") \n",
    "\n",
    "for sibling in bsObj.find(\"table\", {\"id\":\"giftList\"}).tr.next_siblings:   # table标签下的子标签。tr标签的兄弟标签。（同级标签）\n",
    "    # 函数只会调用后面的同级标签。不会调用当前标签。所以会是选择了标题之后的标签。\n",
    "    '''\n",
    "<table>\n",
    "  <tr>标题</tr>\n",
    "  <tr>内容1</tr>\n",
    "  <tr>内容2</tr>\n",
    "</table>\n",
    "    '''\n",
    "    print(sibling)\n",
    "    \n",
    "\n",
    "# 找到一组兄弟标签的最后一个标签。\n",
    "previous_siblings\n",
    "# 找到下一个，单个的兄弟标签。\n",
    "next_sibling\n",
    "# 找到前一个兄弟标签\n",
    "previous_sibling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$15.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 父标签处理\n",
    "# 这段代码会打印。 ../img/gifts/img1.jpg这个图片对应商品的价格。\n",
    "\"\"\"  HTML文档结构\n",
    "<tr>\n",
    "    <td>\n",
    "    <td>\n",
    "    <td>   (3)\n",
    "        \"$15:00\"   (4)\n",
    "    <td>   (2)\n",
    "        <img src=\"../img.gifts/imgs1.jpg\">    (1)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://www.pythonscraping.com/pages/page3.html\"\n",
    "html = urlopen(url)\n",
    "print(bsObj.find(\"img\", {\"src\": \"../img/gifts/img1.jpg\"}).parent.previous_sibling.get_text())\n",
    "# 1:先找到 图片标签 src=\"img/gifts/imgs1.jpg\"\n",
    "# 2:选择图片标签的父标签。例子中的是 <td>\n",
    "# 3:选择td标签的前一个兄弟标签。（previous_sibling）\n",
    "# 4:get_text() 解析出标签价格。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../img/gifts/img1.jpg\n",
      "../img/gifts/img2.jpg\n",
      "../img/gifts/img3.jpg\n",
      "../img/gifts/img4.jpg\n",
      "../img/gifts/img6.jpg\n"
     ]
    }
   ],
   "source": [
    "# 正则表达式与BS4\n",
    "# 过滤出所有的商品图片链接。\n",
    "\n",
    "# <img src=”../img/gifts/img3.jpg“>\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "url = \"http://www.pythonscraping.com/pages/page3.html\"\n",
    "html = urlopen(url)\n",
    "\n",
    "bsObj = BeautifulSoup(html, \"html.parser\")\n",
    "imgaes = bsObj.findAll(\"img\", {\"src\": re.compile(\"\\.\\.\\/img\\/gifts\\/img.*\\.jpg\")})  # re匹配链接。\n",
    "\n",
    "for image in imgaes:\n",
    "    print(image[\"src\"])   # 获取属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过滤得出标签中的属性。\n",
    "\n",
    "# 对一个标签对象。可以这样获得他的全部属性。返回的是字典对象。\n",
    "myTag.attrs\n",
    "\n",
    "# 假设获取属性中的资源位置。src\n",
    "\n",
    "myImgTag.attrs[\"src\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-58-9c186cdd74e4>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-58-9c186cdd74e4>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    <div class=\"body\" id=\"content\"></div>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# BS4 接受允许把特定函数类型当作成 findAll的参数。唯一的限制条件是，函数必须把一个标签作为参数。并且返回结果是布尔值。\n",
    "# BS4 会用这个参数来评估遇到的对象。评估为 True的保留。其它标签剔除出去。\n",
    "\n",
    "soup.findAll(lambda tag: len(tag.attrs) ==2)\n",
    "\n",
    "# 这行代码会找出以下的标签。有两个属性值的标签。 \n",
    "\n",
    "<div class=\"body\" id=\"content\"></div>\n",
    "<span style=”color: red“ class=\"title\"></span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
